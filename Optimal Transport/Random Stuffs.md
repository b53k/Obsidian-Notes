<center> <h1> Random Stuffs </h1></center>
<center><span style="color: red">üóìÔ∏èDate: </span><span style="color: blue">02-21-2023</span></center> 
<center><span style="color: red">üïêTime: </span><span style="color: blue">01:54</span></center><right><span style="color: orange">Bipin Koirala
</span></right><hr>

```toc
	style: number
```
<hr>

## Product Space

In probability theory, a product space is a way of constructing a probability measure on the Cartesian product of two or more measurable spaces. Given a collection of measurable spaces $(\Omega_i,\mathcal{F}_i)$ for $i=1,2,\dots,n$, the product space is defined as the Cartesian product of these spaces:

$$\Omega = \Omega_1 \times \Omega_2 \times \cdots \times \Omega_n,$$

equipped with the product sigma algebra $\mathcal{F} = \mathcal{F}_1 \otimes \mathcal{F}_2 \otimes \cdots \otimes \mathcal{F}_n$. The product sigma algebra is generated by sets of the form $A_1\times A_2 \times \cdots \times A_n$, where $A_i\in\mathcal{F}_i$ for each $i$.

A probability measure on the product space is a function $P:\mathcal{F}\to [0,1]$ that satisfies the following properties:

* *$P(\Omega) = 1$ 
* For any countable collection of pairwise disjoint sets ${A_i}\subseteq \mathcal{F}$, we have $P(\bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$.
* The probability measure $P$ on the product space can be uniquely defined by specifying its values on sets of the form $A_1 \times A_2 \times \cdots \times A_n$, where $A_i\in\mathcal{F}_i$ for each $i$. The product measure $P$ is then defined by:

$$P(A_1 \times A_2 \times \cdots \times A_n) = \prod_{i=1}^n P_i(A_i),$$
where $P_i$ is a probability measure on the measurable space $(\Omega_i,\mathcal{F}_i)$.

The product space is useful for studying probability distributions on high-dimensional spaces, and for defining joint probability distributions of random variables defined on different measurable spaces.

## Fenchel-Rockafellar Duality Theorem

The Fenchel-Rockafellar duality theorem is a result in convex analysis that establishes a duality between two optimization problems. Let $f: X \to \mathbb{R}$ be a convex, lower-semicontinuous function, and let $g: Y \to \mathbb{R}$ be a closed, convex, lower-semicontinuous function. The theorem states that:

$$\min_{x\in X} f(x) = \max_{y\in Y} {-g^*(y) - \langle y, x \rangle},$$

where $g^*$ is the convex conjugate of $g$, defined as:

$$g^*(y) = \sup_{x\in X} {\langle y, x \rangle - g(x)}.$$

In other words, the minimum of $f$ on $X$ is equal to the maximum of a linear function over $Y$, where the slope of the linear function is $y$ and the intercept is $-g^*(y)$.

This duality result has many applications in optimization and related fields, such as machine learning, signal processing, and economics. The theorem is often used to derive optimality conditions for convex optimization problems, which are essential in developing efficient algorithms for solving these problems.

```ad-note
collapse:open

A lower semi-continuous function is a type of function in mathematics that satisfies a certain property.

Informally, a function $f: X \to \mathbb{R}$ is lower semi-continuous at a point $x \in X$ if, for any real number $c$ that is strictly greater than $f(x)$, there exists a small enough neighborhood of $x$ (i.e., a subset of $X$ containing $x$ and some other points) such that the function $f$ is always greater than or equal to $c$ on that neighborhood.

In other words, the function $f$ does not have any sudden jumps or discontinuities at $x$. It may have a "kink" or a "bend" at $x$, but if you zoom in close enough to $x$, the function will not suddenly drop below a certain value.

Formally, a function $f: X \to \mathbb{R}$ is lower semi-continuous at $x \in X$ if, for any $\epsilon > 0$, there exists a neighborhood $U$ of $x$ such that $f(y) > f(x) - \epsilon$ for all $y \in U$.

Lower semi-continuity is a useful concept in many areas of mathematics, including optimization, functional analysis, and partial differential equations. In optimization, for example, lower semi-continuity is a key property for ensuring the existence of optimal solutions to certain types of optimization problems.
```

## On Adaptive Optimal Transport Metrics in the context of Bayesian Optimization

**Abstract**

The effectiveness of adaptive optimal transport metrics in the Bayesian optimization process lies in their ability to better capture the geometry of the search space and to adapt to changes in the objective function.

In traditional Bayesian optimization, a fixed kernel function is used to measure the distance between candidate solutions. This kernel function may not be well-suited to the geometry of the search space, leading to poor performance. By using an adaptive optimal transport metric, the distance measure between solutions can be better tailored to the geometry of the search space, resulting in more effective exploration and exploitation of the search space.

Furthermore, adaptive optimal transport metrics can be updated during the optimization process to reflect changes in the objective function. This allows the metric to better capture the geometry of the search space as the objective function changes, which can lead to more effective optimization.

In summary, using an adaptive optimal transport metric in the Bayesian optimization process can lead to more effective optimization by better capturing the geometry of the search space and adapting to changes in the objective function.

**Introduction**

In the Bayesian optimization process, the goal is to find the global minimum of a function $f(x)$ over a search space $\mathcal{X}$. We can model the function as a Gaussian process with a mean function $\mu(x)$ and a covariance function $k(x,x')$. The goal of the optimization process is to find the value of $x$ that minimizes $f(x)$.

One approach to Bayesian optimization with optimal transport is to use the Wasserstein distance $W_p$ between the probability distributions of the posterior mean and the acquisition function, where the optimal transport plan $\pi$ is given by:
$$\large W_p(\mu_p, \mu_q)^p = \min_{\pi \in \Pi(\mu_p, \mu_q)} \int_{\mathcal{X}\times \mathcal{X}} ||x-x'||^p d\pi(x,x')$$
where $\mu_p$ and $\mu_q$ are the posterior mean distributions of the Gaussian process evaluated at two different points $p$ and $q$, $\Pi(\mu_p, \mu_q)$ is the set of all probability distributions over the space of joint distributions of $\mu_p$ and $\mu_q$, and $| \cdot |$ is a distance metric.

In the adaptive optimal transport metric approach, we update the optimal transport plan based on the information obtained during the optimization process. We can express the update of the optimal transport plan as:
$$\large \pi(x,x') \leftarrow \pi(x,x') + \eta(x)\cdot\Delta(x,x'),$$
where $\eta(x)$ is a weight function that assigns a weight to each point $x$ in the search space, $\Delta(x,x')$ is a distance function that measures the distance between two points $x$ and $x'$, and $0 \leq \eta(x) \leq 1$ for all $x$.

The weight function $\eta(x)$ can be updated during the optimization process based on the performance of the optimization algorithm. For example, we can assign higher weights to regions of the search space where the optimization algorithm has found promising solutions in the past.

The distance function $\Delta(x,x')$ can be any distance metric that is appropriate for the search space. For example, we can use the Euclidean distance for continuous search spaces or the Hamming distance for discrete search spaces.

By updating the optimal transport plan in this way, we can effectively guide the optimization algorithm to explore promising regions of the search space more efficiently. This can result in faster convergence to the global minimum and better performance in high-dimensional search spaces.

### Implementation

Implementing a Bayesian optimization process with an adaptive optimal transport metric involves several steps. Here's a high-level overview of the process:

1.  Define the search space: Define the bounds of the search space for the optimization problem. This could be a set of continuous or discrete variables.
    
2.  Define the objective function: Define the objective function to be optimized. This could be a black-box function that takes a set of input parameters and returns a scalar output value.
    
3.  Choose a prior distribution: Choose a prior distribution over the objective function. This could be a Gaussian process, a random forest, or another type of model.
    
4.  Choose an acquisition function: Choose an acquisition function to select the next set of input parameters to evaluate. This could be expected improvement, probability of improvement, or another function.
    
5.  Define an optimal transport metric: Define an optimal transport metric to measure the distance between candidate solutions. This could be a Wasserstein distance or another metric.
    
6.  Choose a method for adapting the optimal transport metric: Choose a method for adapting the optimal transport metric during the optimization process. This could be a neural network, a Gaussian process, or another method.
    
7.  Initialize the optimization process: Initialize the optimization process by selecting a set of input parameters to evaluate.
    
8.  Evaluate the objective function: Evaluate the objective function at the selected input parameters.
    
9.  Update the prior distribution: Update the prior distribution using the evaluated input parameters and their corresponding objective function values.
    
10.  Update the adaptive optimal transport metric: Update the adaptive optimal transport metric using the evaluated input parameters and their corresponding objective function values.
    
11.  Choose the next input parameters: Choose the next set of input parameters to evaluate using the acquisition function and the adaptive optimal transport metric.
    
12.  Repeat steps 8-11 until convergence: Repeat steps 8-11 until the optimization process converges to a solution.

This is a high-level overview of the process, and the details of each step will depend on the specific implementation. There are several open-source libraries for implementing Bayesian optimization with adaptive optimal transport metrics, such as GPyOpt, which may be helpful to explore.